# Analyze your ANN code with Night System

When I working on a project about ANN, I stucked in code perfomance
analyze. `nvidia-smi` and `torch.cuda` has very limited information in detail.

I found ptrblck use [this](https://github.com/pytorch/pytorch/issues/59692) to analyze cuda stream, [this](https://dev-discuss.pytorch.org/t/using-nsight-systems-to-profile-gpu-workload/59) for gpu workload. Besides, NVIDIA-NSYS [user guide](https://docs.nvidia.com/nsight-systems/UserGuide/index.html) offers detailed CLI parameters.

## NVIDIA configuration 

Full step of [Allow profiling of your GPU](https://developer.nvidia.com/nvidia-development-tools-solutions-err_nvgpuctrperm-permission-issue-performance-counters#SolnTag). I put the linux part here:

### Linux and QNX Mobile Only

* Set the support-gpu-tools device tree property in the GPU device node to "1".
* Recompile the Device Tree following the instructions in the appropriate DRIVE OS SDK Developement Guide:
    * DRIVE OS Linux SDK Development Guide
    * DRIVE OS QNX SDK Development Guide
* Flash updated DTB.
* GPU Debugger and Profiler support should be enabled now.



## 1. Code API

### 1.1 Start and Stop

```python
torch.cuda.cudart().cudaProfilerStart()
# your gpu code
torch.cuda.cudart().cudaProfilerStop()
```

### 1.2 GPU code division

```python
iters = 999
s1 = torch.cuda.Stream(device=device)
s2 = torch.cuda.Stream(device=device)

for i in range(iters):
    
    torch.cuda.nvtx.range_push('iter{}'.format(i))
    
    with torch.cuda.stream(s1):
        # do something in steam 1
        pass
        
    with torch.cuda.stream(s2):
        # do something in steam 2
        pass
                
    torch.cuda.nvtx.range_pop()        
```

## 2. Run your code

Detailed CLI doc [here](https://docs.nvidia.com/nsight-systems/UserGuide/index.html) offers detailed CLI parameters.

This is a ready-to-go command your can have a try.

```bash
nsys profile -w true -t cuda,nvtx,osrt,cudnn,cublas -s cpu  --capture-range=cudaProfilerApi --stop-on-range-end=true --cudabacktrace=all -x true -o <file-name> --force-overwrite true --gpu-metrics-device=<GPU bus id> <python> <script.py>

```

![å›¾ 1](https://s2.loli.net/2022/01/29/pwWBktqFmfe76ZI.png)